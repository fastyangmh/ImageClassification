# parameters configuration
mode: train
root: data/
predefined_dataset: CIFAR10
classes:
  [
    "airplane",
    "automobile",
    "bird",
    "cat",
    "deer",
    "dog",
    "frog",
    "horse",
    "ship",
    "truck",
  ]
max_samples: null
batch_size: 32
num_workers: 0
accelerator: cuda
random_seed: 0
early_stopping: True
patience: 3
devices: auto
default_root_dir: save/
precision: 32
max_epochs: 100
weighted_loss: False
checkpoint_path: null
lr: 1e-3
model_name: lcnet_035
in_chans: 3
last_activation_function_name: Sigmoid
file_extensions: "IMG_EXTENSIONS"
loss_function_name: BCEWithLogitsLoss
examples:
  [
    "examples/CIFAR10/appaloosa_s_001946.png",
    "examples/CIFAR10/auto_s_000561.png",
    "examples/CIFAR10/bufo_marinus_s_001549.png",
    "examples/CIFAR10/gondola_s_000055.png",
    "examples/CIFAR10/wrecker_s_001908.png",
  ]
nni_port: 8081

# transforms configuration
transforms_config:
  train:
    selfdefined.ColorConverter:
      color_space: RGB
    torchvision.Resize:
      - 32
      - 32
    torchvision.RandomHorizontalFlip:
    torchvision.AugMix:
    torchvision.ToTensor:
    torchvision.RandomErasing:

  val:
    selfdefined.ColorConverter:
      color_space: RGB
    torchvision.Resize:
      - 32
      - 32
    torchvision.ToTensor:

  test:
    selfdefined.ColorConverter:
      color_space: RGB
    torchvision.Resize:
      - 32
      - 32
    torchvision.ToTensor:

  predict:
    selfdefined.ColorConverter:
      color_space: RGB
    torchvision.Resize:
      - 32
      - 32
    torchvision.ToTensor:

# target transforms configuration
target_transforms_config:
  train:
    selfdefined.LabelSmoothing:
      alpha: 0.2
      num_classes: 10

  val:
    selfdefined.OneHotEncoder:
      num_classes: 10

  test:
    selfdefined.OneHotEncoder:
      num_classes: 10

  predict:
    selfdefined.OneHotEncoder:
      num_classes: 10

# optimizers configuration
optimizers_config:
  Adam:
    betas:
      - 0.9
      - 0.999
    eps: 1e-08
    weight_decay: 0
    amsgrad: False

# learning rate schedulers configuration
lr_schedulers_config:
  CosineAnnealingLR:
    T_max: 10

# NNI configuration
nni_config:
  searchSpace:
    lr:
      _type: uniform
      _value: [1e-5, 1e-1]
    max_epochs:
      _type: randint
      _value: [1, 50]
  maxTrialNumber: 100
  experimentWorkingDirectory: save/nni-experiments/
  tuner:
    name: TPE
    classArgs:
      optimize_mode: minimize
  trainingService:
    platform: local
