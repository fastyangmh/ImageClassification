# parameters configuration
mode: train
root: data/
predefined_dataset: MNIST
classes:
  [
    "0 - zero",
    "1 - one",
    "2 - two",
    "3 - three",
    "4 - four",
    "5 - five",
    "6 - six",
    "7 - seven",
    "8 - eight",
    "9 - nine",
  ]
max_samples: null
batch_size: 32
num_workers: 0
accelerator: cuda
random_seed: 0
early_stopping: True
patience: 3
devices: auto
default_root_dir: save/
precision: 32
max_epochs: 100
weighted_loss: False
checkpoint_path: null
lr: 1e-3
model_name: lcnet_035
in_chans: 1
last_activation_function_name: Sigmoid
file_extensions: "IMG_EXTENSIONS"
loss_function_name: BCEWithLogitsLoss
examples:
  [
    "examples/MNIST/00000_7.png",
    "examples/MNIST/00001_2.png",
    "examples/MNIST/00002_1.png",
    "examples/MNIST/00003_0.png",
    "examples/MNIST/00004_4.png",
    "examples/MNIST/00007_9.png",
    "examples/MNIST/00011_6.png",
    "examples/MNIST/00061_8.png",
    "examples/MNIST/00433_5.png",
    "examples/MNIST/00449_3.png",
  ]
nni_port: 8081

# transforms configuration
transforms_config:
  train:
    selfdefined.ColorConverter:
      color_space: L
    torchvision.Resize:
      - 32
      - 32
    torchvision.RandomHorizontalFlip:
    torchvision.AugMix:
    torchvision.ToTensor:
    torchvision.RandomErasing:

  val:
    selfdefined.ColorConverter:
      color_space: L
    torchvision.Resize:
      - 32
      - 32
    torchvision.ToTensor:

  test:
    selfdefined.ColorConverter:
      color_space: L
    torchvision.Resize:
      - 32
      - 32
    torchvision.ToTensor:

  predict:
    selfdefined.ColorConverter:
      color_space: L
    torchvision.Resize:
      - 32
      - 32
    torchvision.ToTensor:

# target transforms configuration
target_transforms_config:
  train:
    selfdefined.LabelSmoothing:
      alpha: 0.2
      num_classes: 10

  val:
    selfdefined.OneHotEncoder:
      num_classes: 10

  test:
    selfdefined.OneHotEncoder:
      num_classes: 10

  predict:
    selfdefined.OneHotEncoder:
      num_classes: 10

# optimizers configuration
optimizers_config:
  Adam:
    betas:
      - 0.9
      - 0.999
    eps: 1e-08
    weight_decay: 0
    amsgrad: False

# learning rate schedulers configuration
lr_schedulers_config:
  CosineAnnealingLR:
    T_max: 10

# NNI configuration
nni_config:
  searchSpace:
    lr:
      _type: uniform
      _value: [1e-5, 1e-1]
    max_epochs:
      _type: randint
      _value: [1, 50]
  maxTrialNumber: 100
  experimentWorkingDirectory: save/nni-experiments/
  tuner:
    name: TPE
    classArgs:
      optimize_mode: minimize
  trainingService:
    platform: local
